{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import shapefile\n",
    "from shapely.geometry import Polygon\n",
    "from descartes.patch import PolygonPatch\n",
    "\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "\n",
    "import progressbar\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predtict graph theory to max profit\n",
    "  by predit\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3934693402873666\n",
      "0.2386512185411911\n"
     ]
    }
   ],
   "source": [
    "######## Parameters #########\n",
    "\n",
    "time_zone_interval = 60*8\n",
    "\n",
    "######## Parameters #########\n",
    "\n",
    "\n",
    "\n",
    "######## Function Start ########\n",
    "def time_rounding(x, base=5):\n",
    "    return int(base * round(float(x)/base))\n",
    "\n",
    "\n",
    "def dropoff_prob_matrix(arr):\n",
    "    '''compute the prbability of dropoff\n",
    "    given the picuk zones\n",
    "    return a matrix with row:pickup\n",
    "    col: probility of dropoff'''\n",
    "    total_pickups = arr.sum(axis=1)\n",
    "    dim = arr.shape\n",
    "    result_arr = np.zeros(dim)\n",
    "    for i in range(dim[0]):\n",
    "        for j in range(dim[1]):\n",
    "            if total_pickups[i] == 0:\n",
    "                continue\n",
    "            elif arr[i,j] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                result_arr[i,j] = arr[i,j]/total_pickups[i]\n",
    "    return result_arr\n",
    "\n",
    "\n",
    "\n",
    "def Greedy_Algorithm(start_zone):\n",
    "    '''Greedy algorithm search the at each states\n",
    "    the minimized moving & wait time zone.\n",
    "    return a path, total_trip_time & total_waste'''\n",
    "    \n",
    "      \n",
    "    ## loading data\n",
    "    matrix_PU_time= pd.read_csv('./Matrix/matrix_PU_time.csv',index_col=0)\n",
    "    matrix_PU_time.columns =matrix_PU_time.columns.astype(float)\n",
    "\n",
    "    matrix_PU_time.fillna(value=8*60, inplace=True)\n",
    "    matrix_PU_wait_time = matrix_PU_time.set_index(matrix_PU_time.index.astype(int)).sort_index()\n",
    "    \n",
    "    matrix_zone_distance = pd.read_csv('./Matrix/full_zone_distance_matrix.csv',index_col=0)\n",
    "    matrix_zone_distance.columns =matrix_zone_distance.columns.astype(int)\n",
    "    matrix_zone_distance.index = matrix_zone_distance.index + 1\n",
    "    temp_index = matrix_zone_distance.index\n",
    "    matrix_zone_distance = matrix_zone_distance.T\n",
    "    matrix_zone_distance.index = temp_index\n",
    "    ind_dis = set(matrix_zone_distance.iloc[146].index)\n",
    "    ind_wait_time = set(matrix_PU_wait_time[0].index)\n",
    "    redundant_zones = list(ind_dis.difference(ind_wait_time))\n",
    "    matrix_zone_distance = matrix_zone_distance.drop(redundant_zones, axis=1).drop(list(map(int, redundant_zones)))\n",
    "    matrix_zone_distance[matrix_zone_distance.isna().any(axis=1)]\n",
    "    \n",
    "    matrix_prob_PU_DO_t0 = pd.read_csv('./Matrix/matrix_prob_PU_DO_t0.csv', index_col=0)\n",
    "    matrix_prob_PU_DO_t0.index = matrix_prob_PU_DO_t0.index.astype(int)\n",
    "    matrix_prob_PU_DO_t0.columns = matrix_prob_PU_DO_t0.columns.astype(int)\n",
    "    top_dropoff_zone_t0 = pd.DataFrame(matrix_prob_PU_DO_t0.idxmax(axis=1))\n",
    "    \n",
    "    \n",
    "    top_dropoff_zone_t1 = pd.DataFrame(matrix_prob_PU_DO_t1.idxmax(axis=1))\n",
    "    \n",
    "    result_path = list() # path with zone as node\n",
    "    total_trip_time = 0 # total time that are making $\n",
    "    total_waste_time = 0 # total time waste in move & wait\n",
    "    total_time = 24*60 # time of a day\n",
    "    temp_zone = start_zone # set current zone to starting zone\n",
    "    \n",
    "    while total_time >= 0:\n",
    "        result_path.append(temp_zone)\n",
    "        # compute highest pro drop off zone\n",
    "        dropoff_zone = top_dropoff_zone_t1.iloc[temp_zone][0]\n",
    "        result_path.append(dropoff_zone)\n",
    "        \n",
    "        # compute trip_time between pickup and dropoff zone\n",
    "        dropoff_trip_time =  matrix_zone_distance.iloc[temp_zone,dropoff_zone]\n",
    "        total_trip_time = total_trip_time + dropoff_trip_time # add trip time to total\n",
    "        total_time = total_time - dropoff_trip_time # subtract the trip time from the day\n",
    "        \n",
    "        # compute moving_time to other zones and the wait time in other zones\n",
    "        trip_wait_time_table = pd.DataFrame(np.array(matrix_zone_distance.iloc[260])\n",
    "                                            + np.array(matrix_PU_wait_time[0])).sort_values(by=0)\n",
    "\n",
    "        # looking for the min \n",
    "        local_min_cost_zone = trip_wait_time_table.idxmin()[0]\n",
    "        local_min_cost_time = trip_wait_time_table.min()[0]\n",
    "        \n",
    "        # update current(temp) zone, total_waste time on moving and waiting, and day\n",
    "        temp_zone = local_min_cost_zone\n",
    "        total_waste_time = total_waste_time + local_min_cost_time\n",
    "        total_time = total_time - local_min_cost_time\n",
    "        \n",
    "    return result_path, total_trip_time, total_waste_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Randomized_Greedy_Algorithm(start_zone, randomness=3):\n",
    "\n",
    "    '''Randomized Greedy algorithm search the at each states\n",
    "    the minimized moving & wait time zone. with some randomness\n",
    "    return a path, total_trip_time & total_waste\n",
    "    \n",
    "    Args:\n",
    "        start_zone(int): a int represent TLC zones as\n",
    "        a starting zone of the alg\n",
    "        \n",
    "        randomness(float): between 0 and 1 to given some \n",
    "        randomness like entropy function, but with 1 the most\n",
    "        random and 0 == Greedy Alg\n",
    "        \n",
    "    Retrun:\n",
    "        result_list(list): path of the taxi in a day\n",
    "        \n",
    "        total_trip_time(float): total time that taxi is making \n",
    "            money i.e. serving customers\n",
    "        \n",
    "        total_waste_time(float): time moving and waiting\n",
    "\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    ## loading data\n",
    "    matrix_PU_time= pd.read_csv('./Matrix/matrix_PU_time.csv',index_col=0)\n",
    "    matrix_PU_time.columns =matrix_PU_time.columns.astype(float)\n",
    "\n",
    "    matrix_PU_time.fillna(value=8*60, inplace=True)\n",
    "    matrix_PU_wait_time = matrix_PU_time.set_index(matrix_PU_time.index.astype(int)).sort_index()\n",
    "    \n",
    "    matrix_zone_distance = pd.read_csv('./Matrix/full_zone_distance_matrix.csv',index_col=0)\n",
    "    matrix_zone_distance.columns =matrix_zone_distance.columns.astype(int)\n",
    "    matrix_zone_distance.index = matrix_zone_distance.index + 1\n",
    "    temp_index = matrix_zone_distance.index\n",
    "    matrix_zone_distance = matrix_zone_distance.T\n",
    "    matrix_zone_distance.index = temp_index\n",
    "    ind_dis = set(matrix_zone_distance.iloc[146].index)\n",
    "    ind_wait_time = set(matrix_PU_wait_time[0].index)\n",
    "    redundant_zones = list(ind_dis.difference(ind_wait_time))\n",
    "    matrix_zone_distance = matrix_zone_distance.drop(redundant_zones, axis=1).drop(list(map(int, redundant_zones)))\n",
    "    matrix_zone_distance[matrix_zone_distance.isna().any(axis=1)]\n",
    "    \n",
    "    matrix_prob_PU_DO_t0 = pd.read_csv('./Matrix/matrix_prob_PU_DO_t0.csv', index_col=0)\n",
    "    matrix_prob_PU_DO_t0.index = matrix_prob_PU_DO_t0.index.astype(int)\n",
    "    matrix_prob_PU_DO_t0.columns = matrix_prob_PU_DO_t0.columns.astype(int)\n",
    "    \n",
    "    top_dropoff_zone_t1 = pd.DataFrame(matrix_prob_PU_DO_t1.idxmax(axis=1))\n",
    "    \n",
    "    \n",
    "    random_number = int(-0.2/(.000000000000001-(randomness+0.000001)) +0.812)\n",
    "    if random_number > 20:\n",
    "        random_number = 20\n",
    "    elif random_number < 1:\n",
    "        random_number = 1\n",
    "    result_path = list() # path with zone as node\n",
    "    total_trip_time = 0 # total time that are making $\n",
    "    total_waste_time = 0 # total time waste in move & wait\n",
    "    total_time = 24*60 # time of a day\n",
    "    temp_zone = start_zone # set current zone to starting zone\n",
    "    \n",
    "    while total_time >= 0:\n",
    "        result_path.append(temp_zone)\n",
    "        # compute highest pro drop off zone\n",
    "        dropoff_zone = top_dropoff_zone_t1.iloc[temp_zone][0]\n",
    "        result_path.append(dropoff_zone)\n",
    "        \n",
    "        # compute trip_time between pickup and dropoff zone\n",
    "        dropoff_trip_time =  matrix_zone_distance.iloc[temp_zone,dropoff_zone]\n",
    "        total_trip_time = total_trip_time + dropoff_trip_time # add trip time to total\n",
    "        total_time = total_time - dropoff_trip_time # subtract the trip time from the day\n",
    "        \n",
    "        # compute moving_time to other zones and the wait time in other zones\n",
    "        trip_wait_time_table = pd.DataFrame(np.array(matrix_zone_distance.iloc[260])\n",
    "                                            + np.array(matrix_PU_wait_time[0])).sort_values(by=0)\n",
    "\n",
    "        # looking for the min \n",
    "        trip_wait_time_table = trip_wait_time_table[:20].sample(random_number)\n",
    "        local_min_cost_zone = trip_wait_time_table.idxmin()[0]\n",
    "        local_min_cost_time = trip_wait_time_table.min()[0]\n",
    "        \n",
    "        # update current(temp) zone, total_waste time on moving and waiting, and day\n",
    "        temp_zone = local_min_cost_zone\n",
    "        total_waste_time = total_waste_time + local_min_cost_time\n",
    "        total_time = total_time - local_min_cost_time\n",
    "        \n",
    "    return result_path, total_trip_time, total_waste_time\n",
    "\n",
    "\n",
    "\n",
    "class Exponential:\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "\n",
    "    def prob_less_than_or_equal(self, t):\n",
    "        rate = self.rate * t\n",
    "        return 1 - np.exp(-rate)\n",
    "\n",
    "    def prob_greater_than(self, t):\n",
    "        return 1 - self.prob_less_than_or_equal(t)\n",
    "\n",
    "    def prob_between(self, t1, t2):\n",
    "        p1 = self.prob_less_than_or_equal(t1)\n",
    "        p2 = self.prob_less_than_or_equal(t2)\n",
    "\n",
    "        return p2 - p1\n",
    "\n",
    "\n",
    "expo = Exponential(2)\n",
    "print(expo.prob_less_than_or_equal(0.25))\n",
    "print(expo.prob_between(0.25, 0.5))\n",
    "\n",
    "\n",
    "######## Function End ########"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#read in files' names\n",
    "path = './Data/'  #please use relative path for team's convience\n",
    "file_names = list()\n",
    "for path, subdirs, files in os.walk(path):  #read root and subfolder recursively\n",
    "    for filename in files:\n",
    "        if re.search(pattern=r'csv', string=filename):  #store only csv\n",
    "            # contain both path and file name eg)  './Data/Weather/nyc_weahter.csv\n",
    "            file_names.append(os.path.join(path, filename))\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "file_names\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### No need to rerun  ####\n",
    "## Sampling the data to 1/12 of size\n",
    "sample_frac = 1/12\n",
    "beg_time = time.time()\n",
    "yellow_csv = []\n",
    "green_csv = []\n",
    "fhv_csv = []\n",
    "additional_features_file_names = []\n",
    "count = 0\n",
    "total = len(file_names)\n",
    "bar = progressbar.ProgressBar(max_value=total)\n",
    "\n",
    "for file_name in file_names:\n",
    "    count = count + 1\n",
    "    bar.update(count)# print out the progress and running time\n",
    "    \n",
    "    if re.search(pattern=r'yellow', string=file_name):\n",
    "        df = pd.read_csv(file_name)\n",
    "        df=df.sample(frac=sample_frac, random_state=1)\n",
    "        yellow_csv.append(df)\n",
    "    elif re.search(pattern=r'green', string=file_name):\n",
    "        df = pd.read_csv(file_name)\n",
    "        df=df.sample(frac=sample_frac, random_state=1)\n",
    "        green_csv.append(df)\n",
    "    elif re.search(pattern=r'fhv', string=file_name):\n",
    "        df = pd.read_csv(file_name)\n",
    "        df=df.sample(frac=sample_frac, random_state=1)\n",
    "        fhv_csv.append(df)\n",
    "    else:\n",
    "        time.sleep(0.05)\n",
    "        #not yet loaded into dataframe need to merge manually\n",
    "        additional_features_file_names.append(file_name)\n",
    "        \n",
    "        \n",
    "additional_features_file_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## concat the monthly data into one file for each vehicle type\n",
    "df_yellow = pd.concat(yellow_csv, axis=0)\n",
    "df_green = pd.concat(green_csv, axis=0)\n",
    "df_fhv = pd.concat(fhv_csv, axis=0)\n",
    "\n",
    "# add a column of vehicle_type to each df \n",
    "df_yellow['vehicle_type'] = 'yellow'\n",
    "df_green['vehicle_type'] = 'green'\n",
    "df_fhv['vehicle_type'] = 'fhv'\n",
    "\n",
    "## fhv' columns has different name and var, need to merge manually\n",
    "# common_columns = list(set(df_yellow.columns) & set(df_green.columns)) #common columns for green and yellow only\n",
    "# print(len(common_columns))  # number of common colunmns\n",
    "\n",
    "# # merge yellow and green on their con=mmon columns\n",
    "# df_yellow = df_yellow[common_columns]\n",
    "# df_green = df_green[common_columns]\n",
    "# df_yellow_green = pd.concat([df_yellow,df_green], axis=0)\n",
    "# print(df_yellow_green.shape)  #final shape df\n",
    "\n",
    "## save above process to a single csv for green and yellow data\n",
    "df_yellow.to_csv('yellow.csv')\n",
    "## save green.csv\n",
    "df_green.to_csv('green.csv')\n",
    "##save fhv_csv\n",
    "df_fhv.to_csv('fhv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning:\n",
      "\n",
      "Columns (16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 s, sys: 2.36 s, total: 23.1 s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yellow = pd.read_csv('./Data/yellow.csv')\n",
    "yellow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create timezone with interval 15min\n",
    "yellow['Time_Diff'] = pd.to_datetime(yellow['tpep_dropoff_datetime']) - pd.to_datetime(yellow['tpep_pickup_datetime'])\n",
    "yellow_new = yellow.iloc[:7781158,]\n",
    "yellow_new.shape\n",
    "yellow_new['Time_Diff'].mean()\n",
    "yellow_new['dropoff_datetime'] = yellow_new['tpep_dropoff_datetime'].str[11:13].astype(float) * 60 + yellow_new['tpep_dropoff_datetime'].str[14:16].astype(float) + yellow_new['tpep_dropoff_datetime'].str[17:19].astype(float) / 60\n",
    "yellow_new['pickup_datetime'] = yellow_new['tpep_pickup_datetime'].str[11:13].astype(float) * 60 + yellow_new['tpep_pickup_datetime'].str[14:16].astype(float) + yellow_new['tpep_pickup_datetime'].str[17:19].astype(float) / 60\n",
    "yellow_new['dropoff_timezone'] = (yellow_new['dropoff_datetime'] //time_zone_interval)\n",
    "yellow_new['pickup_timezone'] = (yellow_new['pickup_datetime'] // time_zone_interval)\n",
    "\n",
    "yellow_new['pickup_date'] = pd.to_datetime(yellow_new['tpep_pickup_datetime']).dt.date\n",
    "yellow_new['dropoff_date'] = pd.to_datetime(yellow_new['tpep_dropoff_datetime']).dt.date\n",
    "yellow_new = yellow_new[yellow_new['pickup_date']==yellow_new['dropoff_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7696006, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "loc_ids = list(range(266))\n",
    "num_loc_ids = len(loc_ids)\n",
    "\n",
    "time_zones = list(yellow_new['pickup_timezone'].unique())\n",
    "time_zones = sorted(time_zones)\n",
    "num_time_zones = len(time_zones)\n",
    "print(num_loc_ids)\n",
    "print(num_time_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create 2-d matrix to with each row as PULocationID and each col as the time_zone\n",
    "matrix_PU_time = pd.DataFrame() # create empty dataframe\n",
    "\n",
    "for time_zone in  time_zones:\n",
    "    temp_df = (time_zone_interval / (yellow_new[yellow_new['pickup_timezone']==time_zone]\n",
    "                                    .groupby(['PULocationID'])['DOLocationID']\n",
    "                                    .agg(['count'])))\n",
    "    temp_df.rename(index=str, columns={\"count\": time_zone},inplace=True)\n",
    "    matrix_PU_time = matrix_PU_time.merge(temp_df,\n",
    "                                                how='outer',\n",
    "                                                left_index = True,\n",
    "                                                right_index = True)\n",
    "    \n",
    "matrix_PU_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix_PU_wait_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4c78903aa08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix_PU_wait_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix_PU_wait_time' is not defined"
     ]
    }
   ],
   "source": [
    "matrix_PU_wait_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_PU_time.to_csv('./Matrix/matrix_PU_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_PU_time.fillna(value=time_zone_interval, inplace=True)\n",
    "matrix_PU_wait_time = matrix_PU_time.set_index(matrix_PU_time.index.astype(int)).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_time_PU_DO = np.zeros([num_time_zones,num_loc_ids,num_loc_ids])\n",
    "print(('1d: each time_zone'\n",
    "      +'\\n2d: each pick up zone'\n",
    "      +'\\n3d: each dropoff zone'))\n",
    "arr_time_PU_DO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bar = progressbar.ProgressBar(max_value=num_time_zones-1)\n",
    "for time_zone in range(num_time_zones):\n",
    "    \n",
    "    bar.update(time_zone)# print out the progress and running time\n",
    "    \n",
    "    temp_PU_DO = (yellow_new[yellow_new['pickup_timezone']==time_zone]\n",
    "               .groupby(['PULocationID'])['DOLocationID']\n",
    "               .value_counts()).unstack(fill_value=0)\n",
    "\n",
    "    temp_arr = np.zeros([num_loc_ids,num_loc_ids])\n",
    "    for i in range(num_loc_ids): \n",
    "        for j in range(num_loc_ids):\n",
    "            try:\n",
    "                temp_arr[i,j] = temp_PU_DO.loc[i,j]\n",
    "            except:\n",
    "                continue\n",
    "    arr_time_PU_DO[time_zone] =  temp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_time_PU_DO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a probability array that given a time zone,  it have row as a pickup loc and col as prob(dropoff loc)\n",
    "arr_prob_PU_DO = np.zeros(arr_time_PU_DO.shape)  # create a 3-d array of the same shape of arr_time_PU_DO\n",
    "for time_zone in range(num_time_zones):\n",
    "    arr_prob_PU_DO[time_zone] = dropoff_prob_matrix(arr_time_PU_DO[time_zone])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## loading the distance matrix(compute from the full_yellow.csv)\n",
    "M = 1000000000000 # large number\n",
    "zone_dis = pd.read_csv('./Matrix/zone_distance_matrix.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_zone_distance = pd.read_csv('./Matrix/full_zone_distance_matrix.csv',index_col=0)\n",
    "matrix_zone_distance.index = matrix_zone_distance.index + 1\n",
    "temp_index = matrix_zone_distance.index\n",
    "matrix_zone_distance = matrix_zone_distance.T\n",
    "matrix_zone_distance.index = temp_index\n",
    "matrix_zone_distance\n",
    "matrix_zone_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind_dis = set(matrix_zone_distance.iloc[146].index)\n",
    "ind_wait_time = set(matrix_PU_wait_time[0].index)\n",
    "redundant_zones = list(ind_dis.difference(ind_wait_time))\n",
    "redundant_zones\n",
    "matrix_zone_distance = matrix_zone_distance.drop(redundant_zones, axis=1).drop(list(map(int, redundant_zones)))\n",
    "matrix_zone_distance[matrix_zone_distance.isna().any(axis=1)]\n",
    "matrix_zone_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_zone_distance = pd.read_csv('./Matrix/full_zone_distance_matrix.csv',index_col=0)\n",
    "matrix_zone_distance.index = matrix_zone_distance.index + 1\n",
    "temp_index = matrix_zone_distance.index\n",
    "matrix_zone_distance = matrix_zone_distance.T\n",
    "matrix_zone_distance.index = temp_index\n",
    "ind_dis = set(matrix_zone_distance.iloc[146].index)\n",
    "ind_wait_time = set(matrix_PU_wait_time[0].index)\n",
    "redundant_zones = list(ind_dis.difference(ind_wait_time))\n",
    "matrix_zone_distance = matrix_zone_distance.drop(redundant_zones, axis=1).drop(list(map(int, redundant_zones)))\n",
    "matrix_zone_distance[matrix_zone_distance.isna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_zone_distance\n",
    "matrix_PU_wait_time\n",
    "arr_prob_PU_DO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_prob_PU_DO_t0 = pd.DataFrame(arr_prob_PU_DO[0])\n",
    "matrix_prob_PU_DO_t1 = pd.DataFrame(arr_prob_PU_DO[1])\n",
    "matrix_prob_PU_DO_t2 = pd.DataFrame(arr_prob_PU_DO[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "matrix_prob_PU_DO_t0.to_csv('./Matrix/matrix_prob_PU_DO_t0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_prob_PU_DO_t0 = pd.read_csv('./Matrix/matrix_prob_PU_DO_t0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_prob_PU_DO_t0.iloc[104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_zone_distance.iloc[104,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(np.array(matrix_zone_distance.iloc[260]) + np.array(matrix_PU_wait_time[0])).sort_values(by=0).min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dropoff_zone_t1 = pd.DataFrame(matrix_prob_PU_DO_t1.idxmax(axis=1))\n",
    "top_dropoff_zone_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_dropoff_zone_t1 = pd.DataFrame(matrix_prob_PU_DO_t1.idxmax(axis=1))\n",
    "top_dropoff_zone_t1.iloc[98][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = Randomized_Greedy_Algorithm(66, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxi_graph import graph_path\n",
    "graph_path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rounded_zone_distance = pd.DataFrame()\n",
    "for col in matrix_zone_distance.columns:\n",
    "    matrix_rounded_zone_distance[col] = matrix_zone_distance[col].apply(time_rounding)\n",
    "matrix_rounded_zone_distance = matrix_rounded_zone_distance.replace(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rounded_zone_distance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "matrix_nodes = pd.DataFrame()\n",
    "for col in matrix_rounded_zone_distance.columns:\n",
    "        matrix_nodes[col] = [0 for i in range(5,24*60,5)]\n",
    "matrix_nodes.index = list(range(5,24*60,5))\n",
    "\n",
    "for col in matrix_rounded_zone_distance.columns:\n",
    "    for row in range(5,24*60,5):\n",
    "        matrix_nodes[col].loc[row] = str(col)+','+str(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_round = nx.DiGraph()\n",
    "matrix_nodes = pd.DataFrame()\n",
    "for col in [1,2,3,4]:\n",
    "        matrix_nodes[col] = [0 for i in range(5,12*5,5)]\n",
    "matrix_nodes.index = list(range(5,12*5,5))\n",
    "\n",
    "for col in [1,2,3,4]:\n",
    "    for row in range(5,12*5,5):\n",
    "        matrix_nodes[col].loc[row] = str(col)+','+str(row)\n",
    "        G_round.add_node((col,row),pos=(col,-row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_zone_distance.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_round.nodes()\n",
    "G_round.add_edge((1,5), (1,10))\n",
    "G_round.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_roun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_row = 0\n",
    "count = 0\n",
    "for row in matrix_nodes.index:\n",
    "    count_row += 1\n",
    "    count_col = 0\n",
    "    for col in matrix_nodes.columns:\n",
    "        count_col += 1\n",
    "        if matrix_round_zone_distance[row] \n",
    "        G_round.add_edge(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(22,33))\n",
    "\n",
    "pos = nx.get_node_attributes(G_round, 'pos')\n",
    "# pos = nx.spring_layout(G_round)\n",
    "nx.draw_networkx_nodes(G_round,pos,node_size=10,font_size=7,width=8,alpha=1.0)\n",
    "nx.draw_networkx_edges(G_round,pos,font_size=7,edgelist=G_round.edges(),\n",
    "                       width=2,alpha=0.5,edge_color='b',edge_size=2)\n",
    "\n",
    "\n",
    "nx.draw_networkx_labels(G_round, pos)\n",
    "# nx.draw(G_round, pos, with_labels=True, node_size=0)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zone to zone moving distance in time mins\n",
    "matrix_zone_distance.iloc[217,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_prob_PU_DO_t0[].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_PU_wait_time[0][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_zone = 147\n",
    "pd.DataFrame(np.array(matrix_zone_distance.iloc[current_zone])\n",
    "                                            + np.array(matrix_PU_wait_time[0])).sort_values(by=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
